#!/usr/bin/env python3
"""
Judge Server

This server:
1. Receives attestation packages from the Data Provider
2. Verifies the signature chain against the root CA
3. Verifies the document hash matches the attested hash
4. Sends flagged documents to an LLM for safety evaluation
5. Publishes results publicly
"""

import os
import json
import hashlib
import base64
from pathlib import Path
from datetime import datetime, timezone
from flask import Flask, request, jsonify
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import padding
from cryptography import x509
from cryptography.hazmat.backends import default_backend

app = Flask(__name__)

# Configuration
CA_ROOT_CERT = os.environ.get('CA_ROOT_CERT', '/certs/root-ca.pem')
RESULTS_PATH = os.environ.get('RESULTS_PATH', '/results')
ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY', '')
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')


def load_root_ca():
    """Load the root CA certificate."""
    with open(CA_ROOT_CERT, 'rb') as f:
        return x509.load_pem_x509_certificate(f.read(), default_backend())


def parse_cert_chain(chain_pem: str) -> list:
    """Parse a PEM certificate chain into individual certificates."""
    certs = []
    current_cert = []
    in_cert = False
    
    for line in chain_pem.split('\n'):
        if '-----BEGIN CERTIFICATE-----' in line:
            in_cert = True
            current_cert = [line]
        elif '-----END CERTIFICATE-----' in line:
            current_cert.append(line)
            cert_pem = '\n'.join(current_cert)
            certs.append(x509.load_pem_x509_certificate(
                cert_pem.encode(), default_backend()
            ))
            in_cert = False
            current_cert = []
        elif in_cert:
            current_cert.append(line)
    
    return certs


def verify_cert_chain(chain_certs: list, root_ca: x509.Certificate) -> bool:
    """
    Verify the certificate chain.
    chain_certs should be [end_entity, intermediate, ...]
    """
    if not chain_certs:
        return False
    
    # For a proper implementation, you'd verify each cert is signed by the next
    # and the last intermediate is signed by the root.
    # This is a simplified version for the hackathon.
    
    try:
        # Check the intermediate (last in chain before root) is signed by root
        if len(chain_certs) >= 2:
            intermediate = chain_certs[-1]
            # Verify intermediate is signed by root
            root_ca.public_key().verify(
                intermediate.signature,
                intermediate.tbs_certificate_bytes,
                padding.PKCS1v15(),
                intermediate.signature_hash_algorithm
            )
        
        # Check end entity is signed by intermediate (or root if no intermediate)
        issuer = chain_certs[1] if len(chain_certs) >= 2 else root_ca
        end_entity = chain_certs[0]
        issuer.public_key().verify(
            end_entity.signature,
            end_entity.tbs_certificate_bytes,
            padding.PKCS1v15(),
            end_entity.signature_hash_algorithm
        )
        
        return True
    except Exception as e:
        app.logger.error(f"Certificate chain verification failed: {e}")
        return False


def verify_quote_signature(quote: dict, signature_b64: str, cert: x509.Certificate) -> bool:
    """Verify the quote signature using the end-entity certificate."""
    try:
        quote_bytes = json.dumps(quote, sort_keys=True).encode('utf-8')
        signature = base64.b64decode(signature_b64)
        
        cert.public_key().verify(
            signature,
            quote_bytes,
            padding.PKCS1v15(),
            hashes.SHA256()
        )
        return True
    except Exception as e:
        app.logger.error(f"Quote signature verification failed: {e}")
        return False


def verify_wasm_hash(wasm_b64: str, expected_hash: str) -> bool:
    """Verify the WASM module hash matches the MRENCLAVE in the quote."""
    wasm_bytes = base64.b64decode(wasm_b64)
    actual_hash = hashlib.sha256(wasm_bytes).hexdigest()
    return actual_hash == expected_hash


def verify_document_hash(document: dict, expected_hash: str) -> bool:
    """Verify the document content matches the attested hash."""
    if not document:
        return expected_hash is None
    
    content = base64.b64decode(document['content'])
    actual_hash = hashlib.sha256(content).hexdigest()
    return actual_hash == expected_hash


def evaluate_document_safety(document: dict) -> dict:
    """
    Use an LLM to evaluate if the document is actually unsafe.
    Returns a verdict dict.
    """
    content = base64.b64decode(document['content']).decode('utf-8', errors='replace')
    filename = document['filename']
    
    # Try Anthropic first, then OpenAI, then fall back to a placeholder
    if ANTHROPIC_API_KEY:
        return evaluate_with_anthropic(filename, content)
    elif OPENAI_API_KEY:
        return evaluate_with_openai(filename, content)
    else:
        return {
            'evaluated': False,
            'reason': 'No LLM API key configured',
            'verdict': 'UNKNOWN'
        }


def evaluate_with_anthropic(filename: str, content: str) -> dict:
    """Evaluate document safety using Claude."""
    try:
        import anthropic
        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        
        # Truncate content if too long
        if len(content) > 10000:
            content = content[:10000] + "\n... [truncated]"
        
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1024,
            messages=[{
                "role": "user",
                "content": f"""You are a safety evaluator. A challenger has flagged the following document as potentially unsafe for AI training data. 

Filename: {filename}

Content:
{content}

Please evaluate whether this document contains content that would be inappropriate or unsafe for inclusion in AI training data. Consider:
- Harmful or dangerous information
- Personally identifiable information (PII)
- Copyrighted content that shouldn't be used
- Biased or discriminatory content
- Misinformation

Respond with a JSON object containing:
- "verdict": "UNSAFE", "SAFE", or "UNCERTAIN"
- "reason": A brief explanation of your verdict
- "confidence": "HIGH", "MEDIUM", or "LOW"

Respond ONLY with the JSON object, no other text."""
            }]
        )
        
        response_text = message.content[0].text.strip()
        
        # Try to parse JSON
        try:
            result = json.loads(response_text)
            result['evaluated'] = True
            return result
        except json.JSONDecodeError:
            return {
                'evaluated': True,
                'verdict': 'UNCERTAIN',
                'reason': f'Could not parse LLM response: {response_text[:200]}',
                'confidence': 'LOW'
            }
            
    except Exception as e:
        return {
            'evaluated': False,
            'verdict': 'ERROR',
            'reason': str(e)
        }


def evaluate_with_openai(filename: str, content: str) -> dict:
    """Evaluate document safety using OpenAI."""
    try:
        import openai
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        
        # Truncate content if too long
        if len(content) > 10000:
            content = content[:10000] + "\n... [truncated]"
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""You are a safety evaluator. A challenger has flagged the following document as potentially unsafe for AI training data. 

Filename: {filename}

Content:
{content}

Please evaluate whether this document contains content that would be inappropriate or unsafe for inclusion in AI training data.

Respond with a JSON object containing:
- "verdict": "UNSAFE", "SAFE", or "UNCERTAIN"
- "reason": A brief explanation of your verdict
- "confidence": "HIGH", "MEDIUM", or "LOW"

Respond ONLY with the JSON object."""
            }]
        )
        
        response_text = response.choices[0].message.content.strip()
        
        try:
            result = json.loads(response_text)
            result['evaluated'] = True
            return result
        except json.JSONDecodeError:
            return {
                'evaluated': True,
                'verdict': 'UNCERTAIN',
                'reason': f'Could not parse LLM response: {response_text[:200]}',
                'confidence': 'LOW'
            }
            
    except Exception as e:
        return {
            'evaluated': False,
            'verdict': 'ERROR',
            'reason': str(e)
        }


def publish_result(challenge_id: str, result: dict):
    """Publish the result to the public results directory."""
    results_dir = Path(RESULTS_PATH)
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # Save individual result
    result_file = results_dir / f"{challenge_id}.json"
    with open(result_file, 'w') as f:
        json.dump(result, f, indent=2)
    
    # Update index
    update_results_index(results_dir)


def update_results_index(results_dir: Path):
    """Update the HTML index of all results."""
    results = []
    for result_file in sorted(results_dir.glob('*.json'), reverse=True):
        if result_file.name == 'index.json':
            continue
        try:
            with open(result_file) as f:
                results.append(json.load(f))
        except:
            pass
    
    # Save JSON index
    with open(results_dir / 'index.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    # Generate HTML index
    html = generate_results_html(results)
    with open(results_dir / 'index.html', 'w') as f:
        f.write(html)


def generate_results_html(results: list) -> str:
    """Generate HTML page for results."""
    rows = []
    for r in results:
        verdict_class = {
            'SAFE': 'safe',
            'UNSAFE': 'unsafe',
            'UNCERTAIN': 'uncertain',
            'ERROR': 'error',
            'UNKNOWN': 'unknown',
            'NO_DOCUMENT': 'safe'
        }.get(r.get('verdict', 'UNKNOWN'), 'unknown')
        
        rows.append(f"""
        <tr class="{verdict_class}">
            <td><code>{r.get('challenge_id', 'N/A')}</code></td>
            <td><code>{r.get('wasm_hash', 'N/A')[:16]}...</code></td>
            <td><code>{r.get('dataset_merkle_root', 'N/A')[:16]}...</code></td>
            <td><strong>{r.get('verdict', 'N/A')}</strong></td>
            <td>{r.get('reason', 'N/A')[:100]}</td>
            <td>{r.get('timestamp', 'N/A')}</td>
            <td>{'‚úÖ' if r.get('attestation_valid') else '‚ùå'}</td>
        </tr>
        """)
    
    return f"""<!DOCTYPE html>
<html>
<head>
    <title>TEE Challenge Results</title>
    <meta http-equiv="refresh" content="30">
    <style>
        body {{ font-family: system-ui, sans-serif; margin: 40px; background: #f5f5f5; }}
        h1 {{ color: #333; }}
        table {{ width: 100%; border-collapse: collapse; background: white; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background: #333; color: white; }}
        tr:hover {{ background: #f5f5f5; }}
        tr.safe {{ background: #d4edda; }}
        tr.unsafe {{ background: #f8d7da; }}
        tr.uncertain {{ background: #fff3cd; }}
        tr.error {{ background: #f5c6cb; }}
        tr.unknown {{ background: #e2e3e5; }}
        code {{ background: #eee; padding: 2px 6px; border-radius: 3px; }}
        .info {{ background: #e7f3ff; padding: 15px; border-radius: 8px; margin-bottom: 20px; }}
    </style>
</head>
<body>
    <h1>üîç TEE Challenge Results</h1>
    
    <div class="info">
        <strong>Auto-refreshes every 30 seconds.</strong> 
        Results shown are from attestation packages verified by the Judge.
    </div>
    
    <table>
        <thead>
            <tr>
                <th>Challenge ID</th>
                <th>WASM Hash</th>
                <th>Dataset Root</th>
                <th>Verdict</th>
                <th>Reason</th>
                <th>Timestamp</th>
                <th>Attestation Valid</th>
            </tr>
        </thead>
        <tbody>
            {''.join(rows) if rows else '<tr><td colspan="7" style="text-align:center">No results yet</td></tr>'}
        </tbody>
    </table>
    
    <p style="margin-top: 20px; color: #666;">
        Total challenges: {len(results)}
    </p>
</body>
</html>"""


# =============================================================================
# API Endpoints
# =============================================================================

@app.route('/submit', methods=['POST'])
def submit_attestation():
    """Receive and verify an attestation package from the Data Provider."""
    try:
        data = request.get_json()
        challenge_id = data.get('challenge_id')
        package = data.get('package')
        
        if not challenge_id or not package:
            return jsonify({'success': False, 'error': 'Missing challenge_id or package'}), 400
        
        # Load root CA
        root_ca = load_root_ca()
        
        # Parse the certificate chain
        chain_certs = parse_cert_chain(package['cert_chain'])
        
        # Step 1: Verify certificate chain
        chain_valid = verify_cert_chain(chain_certs, root_ca)
        if not chain_valid:
            result = {
                'challenge_id': challenge_id,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'attestation_valid': False,
                'verdict': 'ERROR',
                'reason': 'Certificate chain verification failed'
            }
            publish_result(challenge_id, result)
            return jsonify({'success': False, 'error': 'Certificate chain invalid'}), 400
        
        # Step 2: Verify quote signature
        quote = package['quote']
        signature_valid = verify_quote_signature(quote, package['signature'], chain_certs[0])
        if not signature_valid:
            result = {
                'challenge_id': challenge_id,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'attestation_valid': False,
                'verdict': 'ERROR',
                'reason': 'Quote signature verification failed'
            }
            publish_result(challenge_id, result)
            return jsonify({'success': False, 'error': 'Quote signature invalid'}), 400
        
        # Step 3: Verify WASM hash matches MRENCLAVE
        wasm_valid = verify_wasm_hash(package['wasm_module'], quote['mrenclave'])
        if not wasm_valid:
            result = {
                'challenge_id': challenge_id,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'attestation_valid': False,
                'verdict': 'ERROR',
                'reason': 'WASM hash does not match MRENCLAVE'
            }
            publish_result(challenge_id, result)
            return jsonify({'success': False, 'error': 'WASM hash mismatch'}), 400
        
        # Step 4: Verify document hash (if document provided)
        document = package.get('document')
        if document:
            doc_valid = verify_document_hash(document, quote['result_document_hash'])
            if not doc_valid:
                result = {
                    'challenge_id': challenge_id,
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'attestation_valid': False,
                    'verdict': 'ERROR',
                    'reason': 'Document hash does not match attestation'
                }
                publish_result(challenge_id, result)
                return jsonify({'success': False, 'error': 'Document hash mismatch'}), 400
        
        # Step 5: Evaluate document safety with LLM (if document provided)
        if document:
            evaluation = evaluate_document_safety(document)
            verdict = evaluation.get('verdict', 'UNKNOWN')
            reason = evaluation.get('reason', 'No reason provided')
        else:
            verdict = 'NO_DOCUMENT'
            reason = 'Challenge found no unsafe documents'
        
        # Create final result
        result = {
            'challenge_id': challenge_id,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'attestation_valid': True,
            'wasm_hash': quote['mrenclave'],
            'dataset_merkle_root': quote['dataset_merkle_root'],
            'challenger_nonce': quote['challenger_nonce'],
            'verdict': verdict,
            'reason': reason,
            'tee_type': quote.get('tee_type', 'unknown')
        }
        
        # Publish result
        publish_result(challenge_id, result)
        
        return jsonify({'success': True, 'result': result})
        
    except Exception as e:
        app.logger.exception("Error processing attestation")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/health')
def health():
    """Health check endpoint."""
    return jsonify({'status': 'healthy'})


if __name__ == '__main__':
    # Initialize results directory with empty index
    results_dir = Path(RESULTS_PATH)
    results_dir.mkdir(parents=True, exist_ok=True)
    update_results_index(results_dir)
    
    app.run(host='0.0.0.0', port=8081, debug=True)